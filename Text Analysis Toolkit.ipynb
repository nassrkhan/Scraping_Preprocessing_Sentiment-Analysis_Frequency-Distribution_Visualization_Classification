{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import itertools \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp= spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(data_text):\n",
    "    documents = []\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    for sen in range(0, len(data_text)):\n",
    "        document = re.sub(r'\\W', ' ', str( data_text[sen]))\n",
    "        document = re.sub(re.escape(string.punctuation), '', document)\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "        document = re.sub(r'\\s+',' ',document, flags=re.I)\n",
    "        document = re.sub(r'^b\\s+', '',document)\n",
    "        document = re.sub(r'^\\s', '',document)\n",
    "        document = re.sub(r'\\s$', '',document)\n",
    "        document = document.lower()\n",
    "\n",
    "        document = document.split()\n",
    "        document = [stemmer.lemmatize(word) for word in document]\n",
    "        document = ' '.join(document)\n",
    "        document = [ word for word in document.split() if word not in stopwords.words(\"english\")]\n",
    "        document = ' '.join(document)\n",
    "        \n",
    "        if(re.search(r'^\\s*$',document)!=None):\n",
    "            continue\n",
    "        if not document:\n",
    "            continue\n",
    "\n",
    "        documents.append(document)\n",
    "    return documents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_script(url):\n",
    "    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36'}\n",
    "    page = requests.get(url,headers=headers).text\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    text = [ p.text for p in soup.find_all('p')]\n",
    "    print(url)\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=['https://www.investopedia.com/terms/d/data-analytics.asp',\n",
    "      'https://www.mastersindatascience.org/learning/what-is-data-analytics/',\n",
    "      'https://searchdatamanagement.techtarget.com/definition/data-analytics',\n",
    "      'https://www.lotame.com/what-is-data-analytics/',\n",
    "      'https://www.thinkful.com/blog/data-analytics-blogs/',\n",
    "      'https://www.tibco.com/reference-center/what-is-data-analytics',\n",
    "      'https://www.simplilearn.com/data-science-vs-big-data-vs-data-analytics-article',\n",
    "      'https://www.ibm.com/analytics/hadoop/big-data-analytics',\n",
    "      'https://www.teradata.com/Blogs/5-Big-Benefits-of-Data-and-Analytics-for-Positive-Business-Outcomes',\n",
    "      'https://www.bmc.com/blogs/data-analytics-vs-data-analysis/',\n",
    "      'https://www.accaglobal.com/in/en/student/exam-support-resources/professional-exams-study-resources/p7/technical-articles/data-analytics.html',\n",
    "      'https://www.stitchdata.com/resources/benefits-of-data-analytics/',\n",
    "      'https://www.qubole.com/big-data-analytics/',\n",
    "      'https://www.dickinson.edu/homepage/1474/data_analytics',\n",
    "      'https://www.dmu.ac.uk/study/courses/postgraduate-courses/data-analytics-msc-degree/data-analytics-msc-degrees.aspx',\n",
    "      'https://www.statistics.com/data-analytics/',\n",
    "      'https://www.scnsoft.com/blog/4-types-of-data-analytics',\n",
    "      'https://www.dataversity.net/brief-history-analytics/',\n",
    "      'https://www.sabanciuniv.edu/en/data-analytics',\n",
    "      'https://www.northeastern.edu/graduate/blog/data-analytics-vs-data-science/',\n",
    "      'https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/making-data-analytics-work-for-you-instead-of-the-other-way-around',\n",
    "      'https://www.eweek.com/big-data-and-analytics/data-analytics-trends/',\n",
    "      'https://corporatefinanceinstitute.com/resources/knowledge/other/data-analytics/',\n",
    "      'https://chartio.com/learn/data-analytics/types-of-data-analysis/',\n",
    "      'https://www.intel.com/content/www/us/en/analytics/what-is-data-analytics.html',\n",
    "      'https://www.omnisci.com/learn/big-data-analytics',\n",
    "      'https://www.lighthouselabs.ca/en/blog/the-five-stages-of-data-analysis',\n",
    "      'https://www.bdo.com.au/en-au/services/advisory/consulting/data-analytics/what-is-data-analytics',\n",
    "      'https://www.journalofaccountancy.com/issues/2016/aug/data-analytics-skills.html',\n",
    "      'https://www.retail-insight-network.com/dashboards/data-analytics-hiring-levels-in-the-retail-industry-rose-in-october-2021/',\n",
    "      'https://www.ironhack.com/en/data-analytics/data-science-data-analytics',\n",
    "      'https://www.comptia.org/blog/best-data-analytics-certifications',\n",
    "      'https://www.kenan-flagler.unc.edu/perspectives/why-data-analytics-matter-to-accountants/',\n",
    "      'https://www.apm.org.uk/resources/what-is-project-management/what-is-project-data-analytics/',\n",
    "      'https://www.techopedia.com/definition/26418/data-analytics',\n",
    "      'https://www.clearrisk.com/risk-management-blog/challenges-of-data-analytics-0',\n",
    "      'https://iterationinsights.com/article/where-to-start-with-the-4-types-of-analytics/',\n",
    "      'https://www.packaging-gateway.com/uncategorised/data-analytics-hiring-levels-in-the-packaging-industry-rose-in-october-2021/',\n",
    "      'https://www.naval-technology.com/analysis/data-analytics-hiring-levels-in-the-naval-industry-rose-in-october-2021/',\n",
    "      'https://www.getsmarter.com/blog/career-advice/difference-data-analytics-data-analysis/',\n",
    "     ]\n",
    "raw_data=[]\n",
    "cleaned_data=[]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop to Scrap and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=1\n",
    "for i in urls:\n",
    "    print(x)\n",
    "    text=url_script(i)\n",
    "    raw_text=[' '.join(text)]\n",
    "    raw_data.extend(raw_text)\n",
    "    clean_text=[' '.join(pre_processing(text))]\n",
    "    cleaned_data.extend(clean_text)\n",
    "    x+=1\n",
    "print(raw_data)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Length of Raw and Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(raw_data))\n",
    "print(len(cleaned_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataframe of Raw and Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['Raw Data']= raw_data\n",
    "df1[\"Cleaned Data\"]= cleaned_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the DataFrame into a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"clean_data.csv\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading DataSet from the CSV File into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob(df2[\"Cleaned Data\"].iloc[0]).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, ngram_range=(1,3),stop_words=stopwords.words('english'))\n",
    "x = tfidfconverter.fit_transform(df2[\"Cleaned Data\"]).toarray()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidfconverter.get_feature_names())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Frequency Distribution of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Cleaned Data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist()\n",
    "for x in str(df2['Cleaned Data'][:]).split():\n",
    "    fdist[x]+=1\n",
    "\n",
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['Polarity']=df2[\"Cleaned Data\"].apply(lambda x : TextBlob(x).sentiment[0])\n",
    "#df2['Subjectivity']=df2[\"Cleaned Data\"].apply(lambda x : TextBlob(x).sentiment[1])\n",
    "df2['Length']=df2[\"Cleaned Data\"].apply(lambda x : len(x.split()))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"N:\\\\Universty_Data\\\\6th_Semester\\\\Topics in Computer Science I (TICS)\\\\TICS Quizzes and Assignments\\\\TICS Assignment-4\\\\scrapdata_sentiment1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"N:\\\\Universty_Data\\\\6th_Semester\\\\Topics in Computer Science I (TICS)\\\\TICS Quizzes and Assignments\\\\TICS Assignment-4\\\\scrapdata_sentiment1.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features based on sentiments (positive, negative, neutral, and compound), polarity subjectivity and length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Negative, Positive, Neutral and Compound values\n",
    "df2[['Polarity', 'Subjectivity']] = df2['Cleaned Data'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "for index, row in df2['Cleaned Data'].iteritems():\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    if neg > pos:\n",
    "        df2.loc[index, 'Class_Label'] = \"negative\"\n",
    "    elif pos > neg:\n",
    "        df2.loc[index, 'Class_Label'] = \"positive\"\n",
    "    else:\n",
    "        df2.loc[index, 'Class_Label'] = \"neutral\"\n",
    "    df2.loc[index, 'neg'] = neg\n",
    "    df2.loc[index, 'neu'] = neu\n",
    "    df2.loc[index, 'pos'] = pos\n",
    "    df2.loc[index, 'compound'] = comp\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "df2[['neg', 'neu', 'pos', 'compound']] = df2['Cleaned Data'].apply(sid.polarity_scores).apply(pd.Series)\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the extracted features in new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"N:\\\\Universty_Data\\\\6th_Semester\\\\Topics in Computer Science I (TICS)\\\\TICS Quizzes and Assignments\\\\TICS Assignment-4\\\\FinalResult_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"N:\\\\Universty_Data\\\\6th_Semester\\\\Topics in Computer Science I (TICS)\\\\TICS Quizzes and Assignments\\\\TICS Assignment-4\\\\FinalResult_data.csv\")\n",
    "df3.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.barplot(data=df3,x=\"Length\",y=\"Subjectivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.barplot(data=df3,x=\"Length\",y=\"Polarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.displot(df3[df3['Polarity']>0]['Polarity'][:50],kde=True)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.pairplot(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "df3['Polarity'].plot(kind='hist')\n",
    "df3['Subjectivity'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "df3['Polarity'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "df3['Subjectivity'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(df3[\"Cleaned Data\"].iloc[0])\n",
    "displacy.render(doc)\n",
    "#ax=plt.axes()\n",
    "#ax.set_facecolor(\"red\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "comment_words = ''\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "for val in df3[\"Cleaned Data\"]:\n",
    "    val = str(val)\n",
    "    tokens = val.split()\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    "wordcloud = WordCloud(width = 800, height = 800,background_color ='white',stopwords = stopwords,min_font_size = 10).generate(comment_words)\n",
    "\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "x=df3[[\"Length\",\"Polarity\",\"Subjectivity\",\"neg\",\"neu\",\"pos\",\"compound\"]].values\n",
    "y=df3[\"Class_Label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train).score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import datasets, model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = model_selection.train_test_split(x, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(('LR',LogisticRegression()))\n",
    "models.append(('KNN',KNeighborsClassifier()))\n",
    "models.append(('DT',DecisionTreeClassifier()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "names=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models:\n",
    "    kfold=model_selection .KFold(n_splits=10)\n",
    "    cv_results=model_selection .cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg=\"%s : %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cl=tree.DecisionTreeClassifier(max_depth=5)\n",
    "dt_cl.fit(x_train, y_train)\n",
    "dt_cl.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prd=dt_cl.predict(x_test)\n",
    "dt_cl.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prd=dt_cl.predict(x_test)\n",
    "confusion_matrix(y_test, y_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cl=ensemble.RandomForestClassifier(n_estimators=100)\n",
    "rf_cl.fit(x_train, y_train)\n",
    "rf_cl.score(x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  =  classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
